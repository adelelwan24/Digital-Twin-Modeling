# Plan2Scene: Converting Floorplans to 3D Scenes


[[Project Page](https://3dlg-hcvc.github.io/plan2scene/), [GitHub](https://github.com/3dlg-hcvc/plan2scene), [Paper](https://arxiv.org/abs/2106.05375)] *CVPR 2021*

<img src='https://raw.githubusercontent.com/3dlg-hcvc/plan2scene/main/docs/img/intro.png' height='300'/>

This system addresses the Plan2Scene task by converting a floorplan and set of photos into a textured 3D mesh model.


## Plan2Scene Stages
<img src='https://raw.githubusercontent.com/3dlg-hcvc/plan2scene/main/docs/img/task-overview.png'/>

The Plan2Scene task consists of several steps: **floorplan vectorization, 3D geometry construction, object placement, photo assignment, texture generation, and texture propagation.**

In this paper, They use simple solutions for earlier steps (floorplan vectorization, 3D geometry construction, object placement), and **_focus primarily on the last two steps_** (**`texture generation`**, and **`texture propagation`**)..

<!-- ## Input and output assumptions
### Input
- Floorplans are usually available as raster images, requiring vectorization. So we assume a vector floorplan as input. We use 'floarpaln' to mean a vector floorplan from here on. 
- The input is a floorplan and a set of photos taken inside a residence, with photos assigned to rooms

### Output
- The output is a 3D mesh of the house with textures
for all architectural surfaces in each room. As a simplifying
assumption, they only represent three surface types in each
room: floor, wall, and ceiling, and assign the same texture for all surfaces of the same type in a room.

## Paper Summary

They address the task of converting a floorplan and a set
of associated photos of a residence into a textured 3D mesh
model, a task which they call Plan2Scene. Our system 
1) lifts a floorplan image to a 3D mesh model.

    - We convert the floorplan to 3D geometry and place fixed 3D objects (e.g., doors, windows, toilets) in the floorplan using a **`rule-based approach`** that retrieves objects from ShapeNet.
2) synthesizes surface textures based on the input photos.
3) infers textures for unobserved surfaces using a graph neural network architecture.

There are three components to there approach: 
1) Neural embedding-based tileable texture synthesis.
2) Texture synthesis for observed surfaces.
3) Texture propagation to unobserved surfaces -->



## Paper Summary

### **Input and Output Assumptions**

**Input Assumptions:**
- **Residential floorplan** and a set of photos without precise camera poses, typical for real estate listings.
- Photos are assigned to specific rooms, though not all rooms have photos.
- The floorplan includes **walls, doors, windows**, and fixed objects like toilets, with categorized rooms (e.g., bedroom, kitchen).

**Output Assumptions:**
- A **3D mesh model** of the entire residence, textured to accurately represent all architectural surfaces including floors, walls, and ceilings.
- Textures are designed to be **tileable** and closely match the surfaces in the photos while correcting artifacts from lighting conditions or image noise.

### **System Components and Performance**

1. **3D Geometry Construction from Floorplans:**
   - Conversion from raster images to **vectorized floorplans** is assumed. The system constructs 3D geometry by placing fixed objects using a **_rule-based approach_** from databases like ShapeNet.

2. **Photo Assignment and Texture Synthesis:**
   - Photos are used as partial observations for texturing room surfaces. For observed surfaces, textures are synthesized using an **encoder-decoder architecture**. For unobserved surfaces, textures are inferred using a **graph neural network (GNN)** which propagates texture information based on room connectivity.

3. **Texture Propagation for Unobserved Surfaces:**
   - Handles texturing of surfaces not visible in any photo by utilizing a GNN. This network uses known textures from observed surfaces and the layout to infer textures for unobserved areas.

4. **Quantitative and Qualitative Evaluation:**
   - Tested against various baselines using metrics like **tileability**, **color accuracy**, and **pattern accuracy**. A user study showed a preference for textures generated by this system, indicating its effectiveness.

5. **Dataset Contributions:**
   - Enhancements to existing floorplan and photo datasets and the creation of new indoor surface texture datasets specifically for training and evaluating the texture synthesis methods.
   - Datasets: 
   [Rent3D++](https://aspis.cmpt.sfu.ca/projects/plan2scene/datasets/rent3dpp/Rent3Dpp.zip), 
   [stationary-textures-dataset-v2](https://aspis.cmpt.sfu.ca/projects/plan2scene/datasets/stationary-textures-v2/stationary-textures-dataset-v2.zip)

## Results of testing the model

Look in the notebooks folder for the demo notebook

There have been several problems in the Plan2Scene model:
1) The mentioned torch and Cuda versions weren't working at all.
   * Tried it on different platforms and didn't work. (Colab and Kaggle)
   * Changed Python version on Colab and this solved this problem.
2) Got an unexpected error saying that these packages were already in the runtime (certifi, google)
   * Colab recommends restarting the runtime (when doing so, The runtime can't connect)
3) In the project, we need to install some packages for their repo. (Result in error)
4) Other package result in module not found on Colab despite making sure they are installed correctly.
